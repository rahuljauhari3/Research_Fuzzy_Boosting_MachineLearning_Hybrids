{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2qSDPcyWwifA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd \n",
        "from keras.layers import LSTM,Dropout,Dense\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z2wINJinzkJu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "from itertools import product\n",
        "import scipy\n",
        "import random\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7GKODCIw_N4",
        "outputId": "58e88482-5577-483f-8700-a118204cf9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(468, 156)\n",
            "(468,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/Users/rahuljauhari/Desktop/research-runoff/Data/merged_imd.csv\")\n",
        "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "df = df.iloc[:, :157]\n",
        "\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "df.set_index('DateTime', inplace=True)\n",
        "monthly_mean = df.resample('M').mean()\n",
        "print(monthly_mean.shape)\n",
        "\n",
        "df_actual = pd.read_excel(\"/Users/rahuljauhari/Desktop/research-runoff/Data/Calibrated and Validated.xlsx\")\n",
        "# select last column\n",
        "observed_runnoff = df_actual['observed']\n",
        "# observed_runnoff.head()\n",
        "print(observed_runnoff.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "avlaLEPQxJiB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def rmse1(yt, yp): #lower the better\n",
        "    return np.sqrt(mean_squared_error(yt, yp))\n",
        "# Kling-Gupta effciency\n",
        "def kge1(yt, yp): #highqer the better\n",
        "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
        "    alpha = np.std(yp) / np.std(yt)\n",
        "    beta = np.mean(yp) / np.mean(yt)\n",
        "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
        "    # r squared\n",
        "def r21(yt, yp): #higher the better\n",
        "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
        "    # Nash-Sutcliffe efficiency\n",
        "def nse(predictions, targets):\n",
        "    return (1-(np.sum((predictions-targets)**2)/np.sum((targets-np.mean(targets))**2)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "m1F1Vx92xuwX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7HtnGM5Sx1pv"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "x_scaled = scaler.fit_transform(monthly_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3PvxpG_ox8yW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test,y_train,y_test = train_test_split(x_scaled,observed_runnoff,test_size=0.2,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOG0OXsLyjEf",
        "outputId": "447db0e1-2e4d-4ad7-d86a-dc60bac89d06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(374, 156)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vct7D1cwzauu"
      },
      "source": [
        "FUZZY_BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fnnjGLhc0S6d"
      },
      "outputs": [],
      "source": [
        "n_neurons=100\n",
        "n_feature= 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EPATVAxIzZsl"
      },
      "outputs": [],
      "source": [
        "# to get all permutaion\n",
        "fRules = list(product([-1.0,0.0,1.0], repeat=n_feature)) \n",
        "\n",
        "# based on article just 100 of them are needed\n",
        "out_fRules = random.sample(fRules, n_neurons)\n",
        "\n",
        "fRules_sigma = K.transpose(out_fRules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Rx5d-uXozvMV"
      },
      "outputs": [],
      "source": [
        "class fuzzy_inference_block(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, i_fmap, mu, sigma):\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.index = i_fmap\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "        super(fuzzy_inference_block, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.mu_map = fRules_sigma * self.mu\n",
        "        self.sigma_map = tf.ones((n_feature, self.output_dim)) * self.sigma\n",
        "        \n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        fMap = inputs[:,n_feature*(self.index):n_feature*(self.index+1)]\n",
        "        # create variables for processing\n",
        "        aligned_x = K.repeat_elements(K.expand_dims(fMap, axis=-1), self.output_dim, -1)\n",
        "        aligned_c = self.mu_map\n",
        "        aligned_s = self.sigma_map\n",
        "\n",
        "\n",
        "        # calculate output of each neuron (fuzzy rule)\n",
        "        phi = K.exp(-K.sum(K.square(aligned_x - aligned_c) / (2 * K.square(aligned_s)),\n",
        "                           axis=-2, keepdims=False))\n",
        "        return phi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cSJsXVwWz0Y9"
      },
      "outputs": [],
      "source": [
        "def fcnn(img_path='network_image.png', n_femap=4, stride=2, mu=3.0, sigma=1.2, dropout=True):\n",
        "    # if stride is 3 => size of feature map will be 2x2\n",
        "    # elif stride is 2 => size of feature map will be 3x3\n",
        "\n",
        "    num_classes = 3\n",
        "\n",
        "    inp = Input((x_train.shape[1],1))\n",
        "\n",
        "    conv1 = Conv1D(3, (2), padding='valid', activation='tanh')(inp)\n",
        "    conv1 = MaxPooling1D((2), strides=(1), padding='same')(conv1)\n",
        "\n",
        "    conv2 = Conv1D(3, (2), padding='valid', activation='tanh')(conv1)\n",
        "    conv2 = MaxPooling1D((2), strides=(1), padding='same')(conv2)\n",
        "    \n",
        "    conv3 = Conv1D(3, (2), padding='valid', activation='tanh')(conv2)\n",
        "    conv3 = MaxPooling1D((2), strides=(1), padding='same')(conv3)\n",
        "\n",
        "    conv4 = Conv1D(3, (2), padding='valid', activation='tanh')(conv3)\n",
        "    conv4 = MaxPooling1D((2), strides=(1), padding='same')(conv4)\n",
        "\n",
        "    conv5 = Conv1D(3, (2), padding='valid', activation='tanh')(conv4)\n",
        "    conv5 = MaxPooling1D((2), strides=(1), padding='same')(conv5)\n",
        "\n",
        "    conv6 = Conv1D(3, (2), padding='valid', activation='tanh')(conv5)\n",
        "    conv6 = MaxPooling1D((2), strides=(1), padding='same')(conv6)\n",
        "\n",
        "    conv7 = Conv1D(3, (2), padding='valid', activation='tanh')(conv6)\n",
        "    conv7 = MaxPooling1D((2), strides=(1), padding='same')(conv7)\n",
        "\n",
        "    conv8 = Conv1D(3, (2), padding='valid', activation='tanh')(conv7)\n",
        "    conv8 = MaxPooling1D((2), strides=(1), padding='same')(conv8)\n",
        "\n",
        "    conv9 = Conv1D(3, (2), padding='valid', activation='tanh')(conv8)\n",
        "    conv9 = MaxPooling1D((2), strides=(1), padding='same')(conv9)\n",
        "\n",
        "    fMaps = Flatten()(conv9)\n",
        "\n",
        "\n",
        "    fuzzy_inference = []\n",
        "    for i in tqdm(range(n_femap)):\n",
        "        f_block = fuzzy_inference_block(output_dim=n_neurons, i_fmap=i, mu=mu, sigma=sigma)(fMaps)\n",
        "        fuzzy_inference.append(f_block)\n",
        "    merged = concatenate(fuzzy_inference, axis=1)\n",
        "\n",
        "    out = Dense(3, activation='tanh')(merged)\n",
        "\n",
        "    model = tf.keras.Model(inp, out)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ABJWJRs1mIV",
        "outputId": "01a72f34-27e5-4091-a018-5d21b49fe0ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 85.60it/s]\n"
          ]
        }
      ],
      "source": [
        "model = fcnn(n_femap=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dt51gvi62Iqr"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss='mse',metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J7gh2IS2drL",
        "outputId": "a7162447-094b-41de-b5e0-f2364313402b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "34/34 [==============================] - 12s 51ms/step - loss: 3029431.7500 - accuracy: 0.0000e+00 - val_loss: 2732183.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3028737.2500 - accuracy: 0.0000e+00 - val_loss: 2732107.2500 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f62c5670>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model.fit(x_train, y_train,validation_split=0.1, batch_size=10, epochs=2,shuffle=False, use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def func(name,x,y):\n",
        "    inv = 0\n",
        "\n",
        "    if name == 'StandardScaler':\n",
        "        scaler = StandardScaler()\n",
        "        x_scaled = scaler.fit_transform(x)\n",
        "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "        x = x_scaled\n",
        "        y = y_scaled\n",
        "        inv = scaler\n",
        "\n",
        "    if name == 'MinMaxScaler':\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        x_scaled = scaler.fit_transform(x)\n",
        "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "        x = x_scaled\n",
        "        y = y_scaled\n",
        "        inv = scaler\n",
        "        \n",
        "    return x, y, inv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x,y,inv = func('MinMaxScaler',monthly_mean,observed_runnoff)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, shuffle=False, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 10ms/step\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "The three columns have been saved to fcnn test.csv.\n"
          ]
        }
      ],
      "source": [
        "y_pred_train = model.predict(x_test)\n",
        "y_pred_test = model.predict(x_test)\n",
        "column_1 = y_pred_train[:, 0]\n",
        "column_2 = y_pred_train[:, 1]\n",
        "column_3 = y_pred_train[:, 2]\n",
        "\n",
        "a = inv.inverse_transform(column_1.reshape(-1,1))\n",
        "b = inv.inverse_transform(column_2.reshape(-1,1))\n",
        "c = inv.inverse_transform(column_3.reshape(-1,1))\n",
        "columns_to_save = np.column_stack((a,b,c))\n",
        "\n",
        "# Define the file name\n",
        "file_name = \"fcnn test.csv\"\n",
        "\n",
        "# Save the columns to a CSV file\n",
        "np.savetxt(file_name, columns_to_save, delimiter=',', header='Column 1,Column 2,Column 3', comments='')\n",
        "\n",
        "print(f\"The three columns have been saved to {file_name}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkd0L3992_wj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def rmse1(yt, yp): #lower the better\n",
        "    return np.sqrt(mean_squared_error(yt, yp))\n",
        "# Kling-Gupta effciency\n",
        "def kge1(yt, yp): #highqer the better\n",
        "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
        "    alpha = np.std(yp) / np.std(yt)+K.epsilon()\n",
        "    beta = np.mean(yp) / np.mean(yt)+K.epsilon()\n",
        "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
        "# Normalized standard Error \n",
        "def nse1(yt, yp): \n",
        "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
        "    # r squared\n",
        "def r21(yt, yp): #higher the better\n",
        "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWnP7omQ3APk",
        "outputId": "30380f12-7bb3-40b4-e667-c0b985ec0d54"
      },
      "outputs": [],
      "source": [
        "yp1 = model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUgNw_fn3Tyq",
        "outputId": "a601e740-207e-409e-d787-cdc47c6cb082"
      },
      "outputs": [],
      "source": [
        "yp1[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Kt-ccw3EJD",
        "outputId": "832c3016-31a7-46cb-fdff-186ff4eac2e4"
      },
      "outputs": [],
      "source": [
        "yp2=model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cnmA3iy3f_T",
        "outputId": "9603aecd-16e7-49ef-dfcf-fc1003da61f0"
      },
      "outputs": [],
      "source": [
        "yp2[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUuAj3Pn6JCJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb3iC-5D3G_D",
        "outputId": "a5d1b5de-801f-4162-e283-b3ef8c2b7d92"
      },
      "outputs": [],
      "source": [
        "print(r2_score(y_train,yp1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HDIHC0u6StA",
        "outputId": "78ed211f-ed3b-4b51-f6c3-409e5fd621c1"
      },
      "outputs": [],
      "source": [
        "print(r2_score(y_test,yp2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
