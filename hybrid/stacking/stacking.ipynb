{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# imort Sequential\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 156)\n",
      "(468,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rahuljauhari/Desktop/research-runoff/Data/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.iloc[:, :157]\n",
    "\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "\n",
    "df_actual = pd.read_excel(\"/Users/rahuljauhari/Desktop/research-runoff/Data/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff = df_actual['observed']\n",
    "# observed_runnoff.head()\n",
    "print(observed_runnoff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def func(name,x,y):\n",
    "    inv = 0\n",
    "\n",
    "    if name == 'StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(x)\n",
    "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "\n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        x_scaled = scaler.fit_transform(x)\n",
    "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    return x, y, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [ 'tanh']\n",
    "optimizer = ['adam']\n",
    "preprocess = ['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahuljauhari/opt/anaconda3/envs/tf1/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:957: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot save file into a non-existent directory: '/Users/rahuljauhari/Desktop/research runoff/results1'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "for act in activation:\n",
    "    for opt in optimizer:\n",
    "        for pre in preprocess:\n",
    "            x,y,inv_scaler= func(pre)\n",
    "            X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Change from StackingClassifier to StackingRegressor\n",
    "            meta_model = LinearRegression()\n",
    "            model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "# ---------------------------\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "\n",
    "            try:\n",
    "                y = np.concatenate((y_pred_train, y_pred), axis=0)\n",
    "                # inverse transform\n",
    "                y_inv = inv_scaler.inverse_transform(y.reshape(-1, 1))\n",
    "                # to csv\n",
    "                pd.DataFrame(y_inv, columns=['Predicted']).to_csv('/Users/rahuljauhari/Desktop/research runoff/results1/imd_gru_lstm_0.2.csv', mode='a', header=True)\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KGE train:  0.8467\n",
      "KGE test:  0.7176\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train_inv = inv_scaler.inverse_transform(y_pred_train.reshape(-1, 1))\n",
    "y_pred_test_inv = inv_scaler.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "y_train__inv = observed_runnoff[:len(y_pred_train_inv)]\n",
    "y_test__inv = observed_runnoff[len(y_pred_train_inv):]\n",
    "print(\"KGE train: \", round(kge1(y_train__inv, y_pred_train_inv),4))\n",
    "print(\"KGE test: \", round(kge1(y_test__inv, y_pred_test_inv),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train__inv = pd.DataFrame(y_train__inv)\n",
    "y_pred_train_inv = pd.DataFrame(y_pred_train_inv)\n",
    "y_train__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_train_inv.reset_index(drop=True, inplace=True)\n",
    "y_train__inv = pd.concat([y_train__inv,y_pred_train_inv],axis=1)\n",
    "y_train__inv.to_csv(f'imd_stacking_train.csv',mode='a',header=True)\n",
    "y_test__inv = pd.DataFrame(y_test__inv)\n",
    "y_pred_test_inv = pd.DataFrame(y_pred_test_inv)\n",
    "y_test__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_test_inv.reset_index(drop=True, inplace=True)\n",
    "y_test__inv = pd.concat([y_test__inv,y_pred_test_inv],axis=1)\n",
    "y_test__inv.to_csv(f'imd_stacking_test.csv',mode='a',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 156)\n",
      "(948, 156)\n",
      "(948,)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "(948,)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "(948,)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "(948,)\n"
     ]
    }
   ],
   "source": [
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_585.csv')\n",
    "df_ssp['TimeDate'] = pd.to_datetime(df_ssp['TimeDate'])\n",
    "df_ssp.set_index('TimeDate', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "scaler = StandardScaler()\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "# y=scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_585_imd_stacking.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_370.csv')\n",
    "df_ssp['TimeDate'] = pd.to_datetime(df_ssp['TimeDate'])\n",
    "df_ssp.set_index('TimeDate', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_370_imd_stacking.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_245.csv')\n",
    "df_ssp['DateTime'] = pd.to_datetime(df_ssp['DateTime'])\n",
    "df_ssp.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df_ssp.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv1 = inv_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "pd.DataFrame(y_inv1).to_csv('SSP_monthly_245_imd_stacking.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_126.csv')\n",
    "df_ssp['DateTime'] = pd.to_datetime(df_ssp['DateTime'])\n",
    "df_ssp.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_126_imd_stacking.csv',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
