{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import RNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import GRU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 156)\n",
      "(468,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rahuljauhari/Desktop/research-runoff/Data/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.iloc[:, :157]\n",
    "\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "\n",
    "df_actual = pd.read_excel(\"/Users/rahuljauhari/Desktop/research-runoff/Data/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff = df_actual['observed']\n",
    "# observed_runnoff.head()\n",
    "print(observed_runnoff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def func(name):\n",
    "    x=0\n",
    "    y=0\n",
    "    inv= 0\n",
    "    if name=='zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm >3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x=x_norm\n",
    "        y=y_norm\n",
    "    if name=='StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled >3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "    return x,y,inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ['StandardScaler']\n",
    "models = [SimpleRNN]\n",
    "activations =['tanh']\n",
    "optimizers = ['adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing: StandardScaler model: <class 'keras.layers.rnn.simple_rnn.SimpleRNN'> activation: tanh optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "for pre in preprocessing:\n",
    "    x,y,inv_scaler= func(pre)\n",
    "    X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)\n",
    "    for mod in models:\n",
    "        for act in activations:\n",
    "            for opt in optimizers:\n",
    "                print('preprocessing:',pre,'model:',mod,'activation:',act,'optimizer:',opt)\n",
    "                model = Sequential()\n",
    "                model.add(mod(64,return_sequences=True, input_shape=(X_train.shape[1], 1),activation=act))\n",
    "                model.add(mod(64,activation=act))  \n",
    "                model.add(Dense(1,activation=act))\n",
    "                model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "                model.fit(x,y,epochs=100,batch_size=10,verbose=0, validation_split=0.1,shuffle=False)\n",
    "                y_pred_test=model.predict(X_test)\n",
    "                y_pred_train=model.predict(X_train)\n",
    "                # try:\n",
    "                #     _ = pd.DataFrame({'model':mod,'activation':act,'optimizer':opt,'preprocessing':pre,'train rmse':rmse1(y_train,y_pred_train),'test rmse':rmse1(y_test,y_pred_test),'train kge':kge1(y_train,y_pred_train),'test kge':kge1(y_test,y_pred_test),'train r2':r21(y_train,y_pred_train),'test r2':r21(y_test,y_pred_test)},index=['model'])\n",
    "                #     _.to_csv('/Users/rahuljauhari/Desktop/research runoff/nasa/imd_result.csv',mode='a',header=True)\n",
    "                # except:\n",
    "                #     print('error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train_inv = inv_scaler.inverse_transform(y_pred_train)\n",
    "y_pred_test_inv = inv_scaler.inverse_transform(y_pred_test)\n",
    "y_train__inv = observed_runnoff[:len(y_pred_train_inv)]\n",
    "y_test__inv = observed_runnoff[len(y_pred_train_inv):]\n",
    "print(\"KGE train: \", round(kge1(y_train__inv, y_pred_train_inv),4))\n",
    "print(\"KGE test: \", round(kge1(y_test__inv, y_pred_test_inv),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train__inv = pd.DataFrame(y_train__inv)\n",
    "y_pred_train_inv = pd.DataFrame(y_pred_train_inv)\n",
    "y_train__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_train_inv.reset_index(drop=True, inplace=True)\n",
    "y_train__inv = pd.concat([y_train__inv,y_pred_train_inv],axis=1)\n",
    "y_train__inv.to_csv(os.getcwd()+'train_rnn_0.2.csv',mode='a',header=True)\n",
    "y_test__inv = pd.DataFrame(y_test__inv)\n",
    "y_pred_test_inv = pd.DataFrame(y_pred_test_inv)\n",
    "y_test__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_test_inv.reset_index(drop=True, inplace=True)\n",
    "y_test__inv = pd.concat([y_test__inv,y_pred_test_inv],axis=1)\n",
    "y_test__inv.to_csv(os.getcwd()+'test_rnn_0.2.csv',mode='a',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x,y= func('StandardScaler')\n",
    "X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(0,observed_runnoff.shape[0]):\n",
    "    l.append(i)\n",
    "plt.scatter(l,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(SimpleRNN(64,return_sequences=True, input_shape=(X_train.shape[1], 1),activation='tanh'))\n",
    "# model1.add(Dropout(0.2))      \n",
    "model1.add(SimpleRNN(64,activation='tanh'))  \n",
    "model1.add(Dense(1,activation='tanh'))\n",
    "model1.compile(optimizer=\"adam\", loss='mse')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train,validation_split=0.1, batch_size=10, epochs=100,shuffle=False, use_multiprocessing=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1 = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kge = []\n",
    "r2=[]\n",
    "rmse =[]\n",
    "# for i in range(yp1.shape[]):\n",
    "kge.append(kge1(y_train, yp1))\n",
    "r2.append(r21(y_train, yp1))\n",
    "rmse.append(rmse1(y_train, yp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(kge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kge = []\n",
    "r2=[]\n",
    "rmse =[]\n",
    "print(yp1.shape)\n",
    "# for i in range(yp1.shape[]):\n",
    "kge.append(kge1(y_test, yp1))\n",
    "r2.append(r21(y_test, yp1))\n",
    "rmse.append(rmse1(y_test, yp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(kge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
