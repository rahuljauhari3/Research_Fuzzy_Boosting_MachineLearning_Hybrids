{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd \n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, Dropout, LSTM, Reshape,MaxPooling1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 156)\n",
      "(468,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rahuljauhari/Desktop/research-runoff/Data/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.iloc[:, :157]\n",
    "\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "\n",
    "df_actual = pd.read_excel(\"/Users/rahuljauhari/Desktop/research-runoff/Data/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff = df_actual['observed']\n",
    "# observed_runnoff.head()\n",
    "print(observed_runnoff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def func(name):\n",
    "    x=0\n",
    "    y=0\n",
    "    inv= 0\n",
    "    if name=='zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm >3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x=x_norm\n",
    "        y=y_norm\n",
    "    if name=='StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled >3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "    return x,y,inv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation = ['relu','sigmoid','tanh']\n",
    "# optimizer =['adam','rmsprop']\n",
    "# preprocess = ['StandardScaler']\n",
    "activation = ['tanh']\n",
    "optimizer =['adam']\n",
    "preprocess = ['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 31ms/step\n",
      "3/3 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "for act in activation:\n",
    "    for opt in optimizer:\n",
    "        for pre in preprocess:\n",
    "            x,y,inv_scaler= func(pre)\n",
    "            X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle=False)\n",
    "            \n",
    "            inputs = Input(shape=(156, 1))\n",
    "            x = Conv1D(filters=64, kernel_size=3, activation=act, trainable=True, padding='same')(inputs)\n",
    "            x = MaxPooling1D((2), strides=(1), padding='same')(x)\n",
    "            \n",
    "            # x = Conv1D(filters=64, kernel_size=3, activation=act, trainable=True, padding='same')(x)\n",
    "            # x = MaxPooling1D((2), strides=(1), padding='same')(x)\n",
    "\n",
    "            x = Flatten(name=\"flatten\")(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "\n",
    "            x = Reshape((156, 64))(x)  \n",
    "            x = GRU(64, activation=act,return_sequences=True)(x)\n",
    "            x = Dropout(0.2)(x) \n",
    "            \n",
    "            x = LSTM(64, activation=act)(x)\n",
    "            x = Dropout(0.2)(x) \n",
    "            \n",
    "            output = Dense(1, activation=act)(x)\n",
    "\n",
    "            model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "            model.compile(optimizer=opt, loss='mse')\n",
    "            model.fit(X_train, y_train, batch_size=100, epochs=100,shuffle=False, use_multiprocessing=True,verbose=0)\n",
    "\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_pred_train_inv = inv_scaler.inverse_transform(y_pred_train)\n",
    "            y_pred_test_inv = inv_scaler.inverse_transform(y_pred_test)\n",
    "            y_train__inv = observed_runnoff[:len(y_pred_train_inv)]\n",
    "            y_test__inv = observed_runnoff[len(y_pred_train_inv):]\n",
    "            try:\n",
    "                _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,\n",
    "                                'KGE train':round(kge1(y_train__inv, y_pred_train_inv),4),'KGE test':round(kge1(y_test__inv, y_pred_test_inv),4)},index=[0])\n",
    "                _.to_csv(os.getcwd()+'/imd_cnn_gru_lstm.csv',mode='a',header=True)\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 31ms/step\n",
      "3/3 [==============================] - 0s 31ms/step\n",
      "KGE train:  0.5295\n",
      "KGE test:  0.5084\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train_inv = inv_scaler.inverse_transform(y_pred_train)\n",
    "y_pred_test_inv = inv_scaler.inverse_transform(y_pred_test)\n",
    "y_train__inv = observed_runnoff[:len(y_pred_train_inv)]\n",
    "y_test__inv = observed_runnoff[len(y_pred_train_inv):]\n",
    "print(\"KGE train: \", round(kge1(y_train__inv, y_pred_train_inv),4))\n",
    "print(\"KGE test: \", round(kge1(y_test__inv, y_pred_test_inv),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train__inv = pd.DataFrame(y_train__inv)\n",
    "y_pred_train_inv = pd.DataFrame(y_pred_train_inv)\n",
    "y_train__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_train_inv.reset_index(drop=True, inplace=True)\n",
    "y_train__inv = pd.concat([y_train__inv,y_pred_train_inv],axis=1)\n",
    "y_train__inv.to_csv(os.getcwd()+'train_cnn_gru_lstm_0.2.csv',mode='a',header=True)\n",
    "y_test__inv = pd.DataFrame(y_test__inv)\n",
    "y_pred_test_inv = pd.DataFrame(y_pred_test_inv)\n",
    "y_test__inv.reset_index(drop=True, inplace=True)\n",
    "y_pred_test_inv.reset_index(drop=True, inplace=True)\n",
    "y_test__inv = pd.concat([y_test__inv,y_pred_test_inv],axis=1)\n",
    "y_test__inv.to_csv(os.getcwd()+'test_cnn_gru_lstm_0.2.csv',mode='a',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def func(name,x,y):\n",
    "    inv = 0\n",
    "\n",
    "    if name == 'StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(x)\n",
    "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "\n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        x_scaled = scaler.fit_transform(x)\n",
    "        y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    return x, y, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 156)\n",
      "(948, 156)\n",
      "30/30 [==============================] - 1s 32ms/step\n",
      "(948, 1)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "30/30 [==============================] - 1s 36ms/step\n",
      "(948, 1)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "30/30 [==============================] - 1s 34ms/step\n",
      "(948, 1)\n",
      "(948, 156)\n",
      "(948, 156)\n",
      "30/30 [==============================] - 1s 32ms/step\n",
      "(948, 1)\n"
     ]
    }
   ],
   "source": [
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_585.csv')\n",
    "df_ssp['TimeDate'] = pd.to_datetime(df_ssp['TimeDate'])\n",
    "df_ssp.set_index('TimeDate', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "scaler = StandardScaler()\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "# y=scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred)\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_585_cnn_gru_lstm_0.2.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_370.csv')\n",
    "df_ssp['TimeDate'] = pd.to_datetime(df_ssp['TimeDate'])\n",
    "df_ssp.set_index('TimeDate', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred)\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_370_cnn_gru_lstm_0.2.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_245.csv')\n",
    "df_ssp['DateTime'] = pd.to_datetime(df_ssp['DateTime'])\n",
    "df_ssp.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df_ssp.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv1 = inv_scaler.inverse_transform(y_pred)\n",
    "pd.DataFrame(y_inv1).to_csv('SSP_monthly_245_cnn_gru_lstm_0.2.csv',header=True)\n",
    "\n",
    "df_ssp = pd.read_csv('/Users/rahuljauhari/Desktop/research-runoff/Data/SSP_monthly_126.csv')\n",
    "df_ssp['DateTime'] = pd.to_datetime(df_ssp['DateTime'])\n",
    "df_ssp.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler',monthly_mean,observed_runnoff)\n",
    "\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred)\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_126_cnn_gru_lstm_0.2.csv',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
