{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# imort Sequential\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 156)\n",
      "(468,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/rahuljauhari/Desktop/research-runoff/Data/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.iloc[:, :157]\n",
    "\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()\n",
    "print(monthly_mean.shape)\n",
    "\n",
    "df_actual = pd.read_excel(\"/Users/rahuljauhari/Desktop/research-runoff/Data/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff = df_actual['observed']\n",
    "# observed_runnoff.head()\n",
    "print(observed_runnoff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def func(name):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    inv = 0\n",
    "    if name == 'zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm > 3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x = x_norm\n",
    "        y = y_norm\n",
    "    if name == 'StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1, 1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled > 3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "\n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "    return x, y, inv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# adam optimizer import\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "# x, y, inv = func('MinMaxScaler')\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x, y, test_size=0.3, shuffle=False)\n",
    "# # validation_data 10% of train data\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     x_train, y_train, test_size=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [ 'linear']\n",
    "optimizer = ['adam']\n",
    "preprocess = ['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [ 'tanh']\n",
    "optimizer = ['adam']\n",
    "preprocess = ['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "for act in activation:\n",
    "    for opt in optimizer:\n",
    "        for pre in preprocess:\n",
    "            x,y,inv_scaler= func(pre)\n",
    "            X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle=False)\n",
    "            model = keras.Sequential()\n",
    "            model.add(GRU(64,return_sequences=True, activation=act, input_shape=(X_train.shape[1],1)))\n",
    "            model.add(Dense(64))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(LSTM(64, activation=act))\n",
    "            model.add(Dense(64))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(layers.Dense(1))\n",
    "            model.compile(optimizer=opt, loss='mse')\n",
    "            model.fit(X_train, y_train, batch_size=10, epochs=100,shuffle=False, use_multiprocessing=True,verbose=0,validation_split=0.1)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            try:\n",
    "                y= np.concatenate((y_pred_train,y_pred),axis=0)\n",
    "                # inverse transform\n",
    "                y_inv = inv_scaler.inverse_transform(y)\n",
    "                # to csv\n",
    "                pd.DataFrame(y_inv).to_csv('/Users/rahuljauhari/Desktop/research runoff/results1/imd_gru_lstm_0.2.csv',mode='a',header=True)\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train_inv = inv_scaler.inverse_transform(y_pred_train)\n",
    "y_pred_test_inv = inv_scaler.inverse_transform(y_pred_test)\n",
    "y_train__inv = observed_runnoff[:len(y_pred_train_inv)]\n",
    "y_test__inv = observed_runnoff[len(y_pred_train_inv):]\n",
    "print(\"KGE train: \", round(kge1(y_train__inv, y_pred_train_inv),4))\n",
    "print(\"KGE test: \", round(kge1(y_test__inv, y_pred_test_inv),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keras tuner for gru lstm\n",
    "# from keras import backend as K\n",
    "# from sklearn.metrics import r2_score\n",
    "# import keras_tuner as kt\n",
    "# from keras_tuner.tuners import RandomSearch\n",
    "# from keras import regularizers\n",
    "# from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     # for i in range(hp.Int('n_layers', 1, 2)):\n",
    "#     model.add(layers.GRU(units=hp.Int('units', min_value=32, max_value=512, step=32), activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh']),  return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "#     model.add(layers.Dense(1, activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh'])))\n",
    "#     model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "#     # for i in range(hp.Int('n_layers', 1, 2)):\n",
    "#     model.add(layers.LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32), activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh']), return_sequences=False))\n",
    "#     model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "#     model.add(layers.Dense(1, activation=hp.Choice('act_' , values=[\n",
    "#         'relu', 'sigmoid', 'linear', 'tanh']), kernel_regularizer=regularizers.l2(hp.Float('l2', 0, 0.5, step=0.1, default=0.2))))\n",
    "#     hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "#     hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam'])\n",
    "#     if hp_optimizer == 'sgd':\n",
    "#         optimizer = SGD(learning_rate=hp_lr)\n",
    "#     elif hp_optimizer == 'rmsprop':\n",
    "#         optimizer = RMSprop(learning_rate=hp_lr)\n",
    "#     else:\n",
    "#         optimizer = Adam(learning_rate=hp_lr)\n",
    "#     model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# tuner = RandomSearch(build_model, objective='mse', max_trials=10,\n",
    "#                      executions_per_trial=1, directory='project', project_name='GRU_LSTM')\n",
    "# tuner.search(x_train, y_train, epochs=100, verbose=1,\n",
    "#              validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "# model = tuner.get_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "# print(\"train \",r2_score(y_train, model.predict(x_train)))\n",
    "# print(\"val \",r2_score(y_val, model.predict(x_val)))\n",
    "# print(\"test \",r2_score(y_test, model.predict(x_test)))\n",
    "# model.summary()\n",
    "# # optimizer used in best model\n",
    "# print(model.optimizer.get_config())\n",
    "# # activation used in best model\n",
    "# model.layers[0].get_config()['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # droupout\n",
    "# model.layers[2].get_config()['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # regularizer\n",
    "# model.layers[5].get_config()['kernel_regularizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
