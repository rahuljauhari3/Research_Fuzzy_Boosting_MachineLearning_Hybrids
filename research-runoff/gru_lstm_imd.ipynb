{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# imort Sequential\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first 157 columns\n",
    "df = df.iloc[:, :157]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()\n",
    "monthly_mean.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = pd.read_excel(\"Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff = df_actual['observed']\n",
    "# observed_runnoff.head()\n",
    "observed_runnoff.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(name):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    inv = 0\n",
    "\n",
    "    if name == 'StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "\n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1, 1))\n",
    "        x = x_scaled\n",
    "        y = y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    return x, y, inv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [ 'tanh','relu','sigmoid']\n",
    "optimizer = ['adam','RMSprop','sgd']\n",
    "preprocess = ['StandardScaler','MinMaxScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "\n",
    "# r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "# while True:\n",
    "for act in activation:\n",
    "    if i ==0:\n",
    "        for opt in optimizer:\n",
    "            if i ==0:\n",
    "                for pre in preprocess:\n",
    "                    if i ==0:\n",
    "                        x,y,inv_scaler= func(pre)\n",
    "                        X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle=False)\n",
    "                        model = keras.Sequential()\n",
    "                        model.add(GRU(128,return_sequences=True, activation=act, input_shape=(X_train.shape[1],1)))\n",
    "                        model.add(Dense(128))\n",
    "                        model.add(LSTM(128, activation=act,return_sequences=True))\n",
    "                        model.add(Dropout(0.5))\n",
    "                        model.add(LSTM(128, activation=act,return_sequences=True))\n",
    "                        model.add(Dense(128))\n",
    "                        model.add(LSTM(128, activation=act))\n",
    "                        model.add(Dropout(0.5))\n",
    "                        model.add(layers.Dense(1))\n",
    "                        model.compile(optimizer=opt, loss='mse')\n",
    "                        model.fit(X_train, y_train, batch_size=32, epochs=5,shuffle=False, use_multiprocessing=True,verbose=0,validation_split=0.1)\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        y_pred_train = model.predict(X_train)\n",
    "                        try:\n",
    "                            if kge1(y_train,y_pred_train) >0.7 and kge1(y_test,y_pred)>0.7:\n",
    "                                _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,'rmse_train':rmse1(y_train,y_pred_train),'rmse_test':rmse1(y_test,y_pred),'kge_train':kge1(y_train,y_pred_train),'kge_test':kge1(y_test,y_pred),'r2_train':r21(y_train,y_pred_train),'r2_test':r21(y_test,y_pred)},index=[0])\n",
    "                                _.to_csv('imd_gru_lstm2.csv',mode='a',header=True)\n",
    "                                i+=1\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                    else:\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "# to csv\n",
    "y_inv_train=inv_scaler.inverse_transform(y_pred_train)\n",
    "y_inv_test=inv_scaler.inverse_transform(y_pred_test)\n",
    "pd.DataFrame(y_inv_train).to_csv('gru_lstm_train1.csv')\n",
    "pd.DataFrame(y_inv_test).to_csv('gru_lstm_test1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ssp = pd.read_csv('SSP_monthly_245.csv')\n",
    "df_ssp['DateTime'] = pd.to_datetime(df_ssp['DateTime'])\n",
    "df_ssp.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df_ssp\n",
    "print(monthly_mean.shape)\n",
    "x,y,inv_scaler= func('StandardScaler')\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred.shape)\n",
    "y_inv = inv_scaler.inverse_transform(y_pred)\n",
    "pd.DataFrame(y_inv).to_csv('SSP_monthly_245_gru_lstm_2.csv',mode='a',header=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimized parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = [ 'sigmoid']\n",
    "optimizer = ['RMSprop']\n",
    "preprocess = ['StandardScaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "a=1\n",
    "while a:\n",
    "    for act in activation:\n",
    "        for opt in optimizer:\n",
    "            for pre in preprocess:\n",
    "                x,y,inv_scaler= func(pre)\n",
    "                X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle=False)\n",
    "                model = keras.Sequential()\n",
    "                model.add(GRU(128,return_sequences=True, activation=act, input_shape=(X_train.shape[1],1)))\n",
    "                model.add(layers.Dense(128))\n",
    "                model.add(LSTM(128, activation='relu'))\n",
    "                model.add(layers.Dense(1))\n",
    "                model.compile(optimizer=opt, loss='mse')\n",
    "                model.fit(X_train, y_train, batch_size=64, epochs=10,shuffle=True, use_multiprocessing=True,verbose=0,validation_split=0.1)\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred_train = model.predict(X_train)\n",
    "                print(kge1(y_train,y_pred_train),kge1(y_test,y_pred))\n",
    "                if kge1(y_train,y_pred_train) >0.7 and kge1(y_test,y_pred)>0.70:\n",
    "                    a=0\n",
    "                    print(a)\n",
    "                # try:\n",
    "                #     y= np.concatenate((y_pred_train,y_pred),axis=0)\n",
    "                #     y_inv = inv_scaler.inverse_transform(y)\n",
    "                #     pd.DataFrame(y_inv).to_csv('/Users/rahuljauhari/Desktop/research-runoff/results1/imd_gru_lstm_0.2.csv',mode='a',header=True)\n",
    "                # except Exception as e:\n",
    "                #     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "# to csv\n",
    "y_inv_train=inv_scaler.inverse_transform(y_pred_train)\n",
    "y_inv_test=inv_scaler.inverse_transform(y_pred_test)\n",
    "pd.DataFrame(y_inv_train).to_csv('gru_lstm_train1.csv')\n",
    "pd.DataFrame(y_inv_test).to_csv('gru_lstm_test1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keras tuner for gru lstm\n",
    "# from keras import backend as K\n",
    "# from sklearn.metrics import r2_score\n",
    "# import keras_tuner as kt\n",
    "# from keras_tuner.tuners import RandomSearch\n",
    "# from keras import regularizers\n",
    "# from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     # for i in range(hp.Int('n_layers', 1, 2)):\n",
    "#     model.add(layers.GRU(units=hp.Int('units', min_value=32, max_value=512, step=32), activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh']),  return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "#     model.add(layers.Dense(1, activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh'])))\n",
    "#     model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "#     # for i in range(hp.Int('n_layers', 1, 2)):\n",
    "#     model.add(layers.LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32), activation=hp.Choice(\n",
    "#         'act_' , values=['relu', 'sigmoid', 'linear', 'tanh']), return_sequences=False))\n",
    "#     model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "#     model.add(layers.Dense(1, activation=hp.Choice('act_' , values=[\n",
    "#         'relu', 'sigmoid', 'linear', 'tanh']), kernel_regularizer=regularizers.l2(hp.Float('l2', 0, 0.5, step=0.1, default=0.2))))\n",
    "#     hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "#     hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam'])\n",
    "#     if hp_optimizer == 'sgd':\n",
    "#         optimizer = SGD(learning_rate=hp_lr)\n",
    "#     elif hp_optimizer == 'rmsprop':\n",
    "#         optimizer = RMSprop(learning_rate=hp_lr)\n",
    "#     else:\n",
    "#         optimizer = Adam(learning_rate=hp_lr)\n",
    "#     model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# tuner = RandomSearch(build_model, objective='mse', max_trials=10,\n",
    "#                      executions_per_trial=1, directory='project', project_name='GRU_LSTM')\n",
    "# tuner.search(x_train, y_train, epochs=100, verbose=1,\n",
    "#              validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "# print(\"train \",r2_score(y_train, best_model.predict(x_train)))\n",
    "# print(\"val \",r2_score(y_val, best_model.predict(x_val)))\n",
    "# print(\"test \",r2_score(y_test, best_model.predict(x_test)))\n",
    "# best_model.summary()\n",
    "# # optimizer used in best model\n",
    "# print(best_model.optimizer.get_config())\n",
    "# # activation used in best model\n",
    "# best_model.layers[0].get_config()['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # droupout\n",
    "# best_model.layers[2].get_config()['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # regularizer\n",
    "# best_model.layers[5].get_config()['kernel_regularizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
