{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpelm import ELM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/rahuljauhari/Desktop/research runoff/final destination/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean = df.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual=pd.read_excel(\"/Users/rahuljauhari/Desktop/research runoff/Calibrated and Validated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last column\n",
    "observed_runnoff=df_actual['observed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def func(name):\n",
    "    x=0\n",
    "    y=0\n",
    "    inv= 0\n",
    "    if name=='zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm >3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x=x_norm\n",
    "        y=y_norm\n",
    "    if name=='StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled >3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "    return x,y,inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # Nash-Sutcliffe efficiency\n",
    "def nse(predictions, targets):\n",
    "    return (1-(np.sum((predictions-targets)**2)/np.sum((targets-np.mean(targets))**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x,y,inv_scaler= func('MinMaxScaler')\n",
    "X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “lin” for linear, “sigm” or “tanh” for non-linear, “rbf_l1”, “rbf_l2” or “rbf_linf” for radial basis function neurons.\n",
    "act = 'tanh'\n",
    "neurons = 64\n",
    "activation = 'relu'\n",
    "elm = ELM(X_train.shape[1], y_train.shape[1],activation,batch=5)\n",
    "elm.add_neurons(neurons, act,)\n",
    "elm.add_neurons(neurons, act)\n",
    "elm.train(X_train, y_train, 'faster2')\n",
    "Y_pred_train = elm.predict(X_train)\n",
    "Y_pred_test = elm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.05584857938017681\n",
      "Testing RMSE:  0.11110732239092555\n",
      "Training KGE:  0.9117697001985273\n",
      "Testing KGE:  0.6178533433523663\n",
      "Training R2:  0.8791177736093172\n",
      "Testing R2:  0.4995441495977966\n",
      "Training NSE:  0.8624953663974426\n",
      "Testing NSE:  0.2275679520693934\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RMSE: \", rmse1(y_train, Y_pred_train))\n",
    "print(\"Testing RMSE: \", rmse1(y_test, Y_pred_test))\n",
    "print(\"Training KGE: \", kge1(y_train, Y_pred_train))\n",
    "print(\"Testing KGE: \", kge1(y_test, Y_pred_test))\n",
    "print(\"Training R2: \", r21(y_train, Y_pred_train))\n",
    "print(\"Testing R2: \", r21(y_test, Y_pred_test))\n",
    "print(\"Training NSE: \", nse(y_train, Y_pred_train))\n",
    "print(\"Testing NSE: \", nse(y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
