{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 10:10:10.448452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd \n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/rahuljauhari/Desktop/research runoff/final destination/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual=pd.read_excel(\"/Users/rahuljauhari/Desktop/research runoff/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff=df_actual['observed']\n",
    "# observed_runnoff.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def func(name):\n",
    "    x=0\n",
    "    y=0\n",
    "    inv= 0\n",
    "    if name=='zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm >3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x=x_norm\n",
    "        y=y_norm\n",
    "    if name=='StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled >3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "    return x,y,inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['relu','linear','sigmoid']\n",
    "optimizer =['adam','rmsprop','sgd']\n",
    "preprocess = ['MinMaxScaler','StandardScaler','zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# adam optimizer import\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "x,y,inv = func('MinMaxScaler')\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)\n",
    "# validation_data 10% of train data\n",
    "x_train, x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from project/GRU_RNN/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# keras tuner for gru rnn\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras import regularizers\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.GRU(units=hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "    model.add(layers.Dense(hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh'])))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "    model.add(layers.SimpleRNN(units=hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),return_sequences=False))\n",
    "    model.add(layers.Dense(1,activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),kernel_regularizer=regularizers.l2(hp.Float('l2', 0, 0.5, step=0.1, default=0.2))))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam'])\n",
    "\n",
    "    if hp_optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=hp_lr)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=hp_lr)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner = RandomSearch( build_model, objective='mse', max_trials=10, executions_per_trial=1,directory='project', project_name='GRU_RNN')\n",
    "tuner.search(x_train, y_train, epochs=100,verbose=0,validation_data=(x_val, y_val),callbacks = [early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 174, 128)          50304     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 174, 128)          16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 174, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,841\n",
      "Trainable params: 99,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print best model summary\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 41ms/step\n",
      "<class 'numpy.ndarray'>\n",
      "10/10 [==============================] - 0s 40ms/step\n",
      "train  0.4481372708702872\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "val  0.5744090955468866\n",
      "5/5 [==============================] - 0s 38ms/step\n",
      "test  0.45550361964457664\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 174, 128)          50304     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 174, 128)          16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 174, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,841\n",
      "Trainable params: 99,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "{'name': 'SGD', 'learning_rate': 0.01, 'decay': 0.0, 'momentum': 0.0, 'nesterov': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tanh'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "from sklearn.metrics import r2_score\n",
    "print(type(best_model.predict(x_train)))\n",
    "print(\"train \",r2_score(y_train, best_model.predict(x_train)))\n",
    "print(\"val \",r2_score(y_val, best_model.predict(x_val)))\n",
    "print(\"test \",r2_score(y_test, best_model.predict(x_test)))\n",
    "best_model.summary()\n",
    "# optimizer used in best model\n",
    "print(best_model.optimizer.get_config())\n",
    "# activation used in best model\n",
    "best_model.layers[0].get_config()['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropout \n",
    "best_model.layers[2].get_config()['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'L2', 'config': {'l2': 0.4000000059604645}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular\n",
    "best_model.layers[4].get_config()['kernel_regularizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score\n",
    "# for act in activation:\n",
    "#     for opt in optimizer:\n",
    "#         for pre in preprocess:\n",
    "#             x,y,inv_scaler= func(pre)\n",
    "#             X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)\n",
    "#             model = keras.Sequential()\n",
    "#             model.add(GRU(64,return_sequences=True, activation=act, input_shape=(X_train.shape[1],1)))\n",
    "#             model.add(Dense(64))\n",
    "#             model.add(Dropout(0.5))\n",
    "#             model.add(SimpleRNN(64, activation=act))\n",
    "#             model.add(Dense(64))\n",
    "#             model.add(Dropout(0.5))\n",
    "#             model.add(layers.Dense(1))\n",
    "#             model.compile(optimizer=opt, loss='mse')\n",
    "#             model.fit(X_train, y_train, batch_size=10, epochs=100,shuffle=False, use_multiprocessing=True,verbose=0,validation_split=0.1)\n",
    "#             y_pred = model.predict(X_test)\n",
    "#             y_pred_train = model.predict(X_train)\n",
    "#             try:\n",
    "#                 _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,'r2_train':r2_score(y_train,y_pred_train),'r2_test':r2_score(y_test,y_pred)},index=[0])\n",
    "#                 # _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,'rmse_train':rmse1(y_train,y_pred_train),'rmse_test':rmse1(y_test,y_pred),'kge_train':kge1(y_train,y_pred_train),'kge_test':kge1(y_test,y_pred),'r2_train':r21(y_train,y_pred_train),'r2_test':r21(y_test,y_pred)},index=[0])\n",
    "#                 _.to_csv('/Users/rahuljauhari/Desktop/research runoff/results1/imd_rnn_gru1.csv',mode='a',header=True)\n",
    "#             except Exception as e:\n",
    "#                 print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
