{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 10:10:58.547974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd \n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/rahuljauhari/Desktop/research runoff/final destination/merged_imd.csv\")\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "df.set_index('DateTime', inplace=True)\n",
    "monthly_mean = df.resample('M').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual=pd.read_excel(\"/Users/rahuljauhari/Desktop/research runoff/Calibrated and Validated.xlsx\")\n",
    "# select last column\n",
    "observed_runnoff=df_actual['observed']\n",
    "# observed_runnoff.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "def func(name):\n",
    "    x=0\n",
    "    y=0\n",
    "    inv= 0\n",
    "    if name=='zscore':\n",
    "        x_norm = zscore(monthly_mean)\n",
    "        y_norm = zscore(observed_runnoff)\n",
    "        x_norm[x_norm > 3] = 2.8\n",
    "        x_norm[x_norm < -3] = -2.8\n",
    "        y_norm[y_norm >3] = 2.8\n",
    "        y_norm[y_norm < -3] = -2.8\n",
    "        x=x_norm\n",
    "        y=y_norm\n",
    "    if name=='StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x_scaled[x_scaled > 3] = 2.8\n",
    "        x_scaled[x_scaled < -3] = -2.8\n",
    "        y_scaled[y_scaled >3] = 2.8\n",
    "        y_scaled[y_scaled < -3] = -2.8\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "        \n",
    "    if name == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        x_scaled = scaler.fit_transform(monthly_mean)\n",
    "        y_scaled = scaler.fit_transform(observed_runnoff.values.reshape(-1,1))\n",
    "        x=      x_scaled  \n",
    "        y=y_scaled\n",
    "        inv = scaler\n",
    "    return x,y,inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse1(yt, yp): #lower the better\n",
    "    return np.sqrt(mean_squared_error(yt, yp))\n",
    "# Kling-Gupta effciency\n",
    "def kge1(yt, yp): #highqer the better\n",
    "    r = np.corrcoef(yt, yp,rowvar=False)[0, 1]\n",
    "    alpha = np.std(yp) / np.std(yt)\n",
    "    beta = np.mean(yp) / np.mean(yt)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "# Normalized standard Error \n",
    "def nse1(yt, yp): \n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)\n",
    "    # r squared\n",
    "def r21(yt, yp): #higher the better\n",
    "    return 1 - np.sum((yt - yp)**2) / np.sum((yt - np.mean(yt))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['relu','linear','sigmoid']\n",
    "optimizer =['adam','rmsprop','sgd']\n",
    "preprocess = ['zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# adam optimizer import\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "x,y,inv = func('MinMaxScaler')\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)\n",
    "# validation_data 10% of train data\n",
    "x_train, x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 33s]\n",
      "mse: nan\n",
      "\n",
      "Best mse So Far: 0.026383042335510254\n",
      "Total elapsed time: 00h 01m 30s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "256               |192               |units\n",
      "relu              |tanh              |act_\n",
      "0.2               |0.4               |dropout_1\n",
      "0.4               |0                 |l2\n",
      "0.001             |0.0001            |learning_rate\n",
      "rmsprop           |adam              |optimizer\n",
      "\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 11s 817ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 8s 793ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 8s 789ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m early_stopping \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     30\u001b[0m tuner \u001b[39m=\u001b[39m RandomSearch( build_model, objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, max_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, executions_per_trial\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproject\u001b[39m\u001b[39m'\u001b[39m, project_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGRU_RNN_LSTM\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(x_val, y_val),callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n\u001b[1;32m     32\u001b[0m best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_models()[\u001b[39m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:227\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_trial_end(trial)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:331\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_trial_end\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[1;32m    326\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mend_trial(trial)\n\u001b[1;32m    332\u001b[0m     \u001b[39m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display\u001b[39m.\u001b[39mon_trial_end(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/oracle.py:435\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry(trial):\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_order\u001b[39m.\u001b[39mappend(trial\u001b[39m.\u001b[39mtrial_id)\n\u001b[0;32m--> 435\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_consecutive_failures()\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/oracle.py:388\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m     consecutive_failures \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m consecutive_failures \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m--> 388\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mNumber of consecutive failures excceeded the limit \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    389\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mof \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_consecutive_failed_trials\u001b[39m}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    390\u001b[0m         \u001b[39m+\u001b[39;49m trial\u001b[39m.\u001b[39;49mmessage\n\u001b[1;32m    391\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.GRU(units=hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "    model.add(layers.Dense(hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh'])))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "    model.add(layers.SimpleRNN(units=hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),return_sequences=True))\n",
    "    model.add(layers.Dense(1,activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),kernel_regularizer=regularizers.l2(hp.Float('l2', 0, 0.5, step=0.1, default=0.2))))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "    model.add(layers.LSTM(units=hp.Int('units',min_value=32,max_value=512,step=32),activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),return_sequences=False))\n",
    "    model.add(layers.Dense(1,activation=hp.Choice('act_' , values=['relu', 'sigmoid','linear','tanh']),kernel_regularizer=regularizers.l2(hp.Float('l2', 0, 0.5, step=0.1, default=0.2))))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.2)))\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_optimizer = hp.Choice('optimizer', values=['sgd', 'rmsprop', 'adam'])\n",
    "\n",
    "    if hp_optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=hp_lr)\n",
    "    elif hp_optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=hp_lr)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=hp_lr)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner = RandomSearch( build_model, objective='mse', max_trials=10, executions_per_trial=1, directory='project', project_name='GRU_RNN_LSTM')\n",
    "tuner.search(x_train, y_train, epochs=100,verbose=1,validation_data=(x_val, y_val),callbacks=[early_stopping])\n",
    "best_model = tuner.get_best_models()[0]\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"train \",r2_score(y_train, best_model.predict(x_train)))\n",
    "print(\"val \",r2_score(y_val, best_model.predict(x_val)))\n",
    "print(\"test \",r2_score(y_test, best_model.predict(x_test)))\n",
    "best_model.summary()\n",
    "# optimizer used in best model\n",
    "print(best_model.optimizer.get_config())\n",
    "# activation used in best model\n",
    "best_model.layers[0].get_config()['activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "# for act in activation:\n",
    "#     for opt in optimizer:\n",
    "#         for pre in preprocess:\n",
    "#             x,y,inv_scaler= func(pre)\n",
    "#             X_train, X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,shuffle=False)\n",
    "#             model = keras.Sequential()\n",
    "#             model.add(LSTM(64,return_sequences=True, activation=act, input_shape=(X_train.shape[1],1)))\n",
    "#             model.add(Dense(64))\n",
    "#             model.add(Dropout(0.5))\n",
    "#             model.add(GRU(64, activation=act,return_sequences=True))\n",
    "#             model.add(Dense(64))\n",
    "#             model.add(Dropout(0.5))\n",
    "#             model.add(SimpleRNN(64, activation=act))\n",
    "#             model.add(Dense(64))\n",
    "#             model.add(Dropout(0.5))\n",
    "#             model.add(layers.Dense(1))\n",
    "#             model.compile(optimizer=opt, loss='mse')\n",
    "#             model.fit(X_train, y_train, batch_size=10, epochs=100,shuffle=False, use_multiprocessing=True,verbose=0,validation_split=0.1)\n",
    "#             y_pred = model.predict(X_test)\n",
    "#             y_pred_train = model.predict(X_train)\n",
    "#             try:\n",
    "#                 _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,'r2_train':r2_score(y_train,y_pred_train),'r2_test':r2_score(y_test,y_pred)},index=[0])\n",
    "#                 # _ = pd.DataFrame({'pre':pre,'act':act,'opt':opt,'rmse_train':rmse1(y_train,y_pred_train),'rmse_test':rmse1(y_test,y_pred),'kge_train':kge1(y_train,y_pred_train),'kge_test':kge1(y_test,y_pred),'r2_train':r21(y_train,y_pred_train),'r2_test':r21(y_test,y_pred)},index=[0])\n",
    "#                 _.to_csv('/Users/rahuljauhari/Desktop/research runoff/results/imd_gru_lstm_rnn.csv',mode='a',header=True)\n",
    "#             except Exception as e:\n",
    "#                 print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a19adc57dc9b86607f700ef6ca47dcfa3c63db12d19ee8d5249422558c9c076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
